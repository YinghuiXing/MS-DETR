# 10271
# nohup python -m torch.distributed.launch --nproc_per_node=4 --master_port 49104  fusion_main.py --exp_config exp_config/23_5_25/exp_24.yaml --output_dir /data/wangsong/results/23_5_25/exp24 --action train > ../DAB-DETR-nohup/ms-detr/23_5_25_24_nohup &
# python fusion_main.py --output_dir /data/wangsong/results/23_5_25/exp24 --action test --resume /data/wangsong/results/23_5_25/exp24/checkpoint.pth --exp_config exp_config/23_5_25/exp_24.yaml --visible_devices 2
TRAIN:
  epochs: 20
  lr_drop: [10, ]
MODEL:
  MS_DETR:
    use_dab: False
    num_feature_levels: 4
    num_queries: 300
    content_embedding: False
  TRANSFORMER:
    dim_feedforward: 1024
    num_feature_levels: 4
    ENCODER:
      layers_rgb: 6
      layers_t: 6
      pre_norm: False
    DECODER:
      pre_norm: False
      use_region_ca: False

DATASET:
  KAIST:
    root_dirs_train: ['/data/wangsong/datasets/KAIST', ]
    root_dirs_test: ['/data/wangsong/datasets/KAIST', ]
  TRANSFORMS:
    mixup_flag: True
    RANDAUGMENT:
      flag: True
      aug_space: 'geometric'
      num: 2
      level: 5
      random: True
EXPERIMENT:
  pretrain_model_path: '/data/wangsong/pretrain_models/r50_deformable_detr_plus_iterative_bbox_refinement-checkpoint.pth'